{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import dlib\n",
    "img_dir='floyd\\input\\dataset\\\\'\n",
    "from lab2_landmarks import run_dlib_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(attribute1,testsize,pictureshape):#testsize=percentage of test data \n",
    "    img_dir='floyd\\input\\dataset\\\\'\n",
    "    noise = pd.read_csv('noise_classified.csv',header=None)\n",
    "    labels_noise= pd.read_csv(\"attribute_list.csv\",skiprows=1)\n",
    "    labels_noise['noise']=noise.loc[:,1]\n",
    "    labels= labels_noise[labels_noise['noise']==1]\n",
    "    attribute=attribute1\n",
    "    train_test_data=labels.loc[:,['file_name',attribute]]\n",
    "    train_test_data.loc[:,['file_name',attribute]]\n",
    "    train_test_data[attribute]= train_test_data[attribute].apply(lambda x: 0 if x < 1  else 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train, test = train_test_split(train_test_data, test_size=testsize)\n",
    "    y_train= np.array(train[attribute]).T\n",
    "    y_test=np.array(test[attribute]).T\n",
    "    train.shape[0]\n",
    "    picture_shape=pictureshape\n",
    "    \n",
    "    i=0\n",
    "    x_train=np.zeros((len(train[attribute]),picture_shape[0],picture_shape[1],3))\n",
    "    for x in list(train['file_name']):\n",
    "        temp= image.load_img(img_dir+str(x)+'.png',target_size=(picture_shape))\n",
    "        x_train[i,:,:,:]=image.img_to_array(temp)\n",
    "        i=i+1\n",
    "    i=0\n",
    "    x_test=np.zeros((len(test[attribute]),picture_shape[0],picture_shape[1],3))\n",
    "    for x in list(test['file_name']):\n",
    "        temp= image.load_img(img_dir+str(x)+'.png',target_size=(picture_shape))\n",
    "        x_test[i,:,:,:]=image.img_to_array(temp)\n",
    "        i=i+1\n",
    "    x_train,x_test = x_train/255,x_test/255\n",
    "    return x_train,y_train,x_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfeatures=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = pd.read_csv('noise_classified.csv',header=None)\n",
    "labels_noise= pd.read_csv(\"attribute_list.csv\",skiprows=1)\n",
    "labels_noise['noise']=noise.loc[:,1]\n",
    "labels= labels_noise[labels_noise['noise']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute='smiling'\n",
    "train_test_data=labels.loc[:,['file_name',attribute]]\n",
    "train_test_data.loc[:,['file_name',attribute]]\n",
    "train_test_data[attribute]= train_test_data[attribute].apply(lambda x: 0 if x < 1  else 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "train, test = train_test_split(train_test_data, test_size=.2)\n",
    "y_train= np.array(train[attribute]).T\n",
    "y_test=np.array(test[attribute]).T\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab2_landmarks import run_dlib_shape\n",
    "i=0\n",
    "x_train=np.zeros((len(train[attribute]),68,2))\n",
    "from keras.preprocessing import image\n",
    "for x in list(train['file_name']):\n",
    "    img= image.load_img(img_dir+str(x)+'.png',target_size=None,interpolation='bicubic')\n",
    "    img=image.img_to_array(img)\n",
    "    x_train[i,:,:], _=run_dlib_shape(img)\n",
    "    i=i+1\n",
    "\n",
    "i=0\n",
    "x_test=np.zeros((len(test[attribute]),68,2))    \n",
    "for x in list(test['file_name']):\n",
    "    img= image.load_img(img_dir+str(x)+'.png',target_size=None,interpolation='bicubic')\n",
    "    img=image.img_to_array(img)\n",
    "    x_test[i,:,:], _=run_dlib_shape(img)\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-8db92fb03dee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#plt.scatter(x_train[15,:,0],x_train[15,:,1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: scatter() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "\n",
    "#plt.scatter(x_train[15,:,0],x_train[15,:,1])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3536, 68, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119., 137., 153., 168., 182., 194., 204., 212., 215., 211., 202.,\n",
       "       191., 179., 166., 151., 135., 118., 111., 103., 100., 101., 106.,\n",
       "       106., 102., 101., 103., 110., 126., 136., 146., 156., 162., 164.,\n",
       "       165., 164., 162., 127., 122., 122., 131., 135., 134., 130., 122.,\n",
       "       121., 127., 134., 134., 181., 177., 175., 176., 175., 177., 181.,\n",
       "       191., 196., 196., 195., 191., 180., 179., 180., 179., 181., 189.,\n",
       "       190., 189.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= image.load_img(img_dir+'1'+'.png',target_size=None,interpolation='bicubic')\n",
    "img=image.img_to_array(img)\n",
    "x_train[1,:,:], _=run_dlib_shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facefeaturesdlib(attribute1,testsize,pictureshape):\n",
    "    noise = pd.read_csv('noise_classified.csv',header=None)\n",
    "    labels_noise= pd.read_csv(\"attribute_list.csv\",skiprows=1)\n",
    "    labels_noise['noise']=noise.loc[:,1]\n",
    "    labels= labels_noise[labels_noise['noise']==1]\n",
    "    attribute=attribute1\n",
    "    train_test_data=labels.loc[:,['file_name',attribute]]\n",
    "    train_test_data.loc[:,['file_name',attribute]]\n",
    "    train_test_data[attribute]= train_test_data[attribute].apply(lambda x: 0 if x < 1  else 1)\n",
    "    train, test = train_test_split(train_test_data, test_size=testsize)\n",
    "    y_train= np.array(train[attribute]).T\n",
    "    y_test=np.array(test[attribute]).T\n",
    "    y_train.shape\n",
    "    \n",
    "    i=0\n",
    "    x_train=np.zeros((len(train[attribute]),68,2))\n",
    "    from keras.preprocessing import image\n",
    "    for x in list(train['file_name']):\n",
    "        img= image.load_img(img_dir+str(x)+'.png',target_size=None,interpolation='bicubic')\n",
    "        img=image.img_to_array(img)\n",
    "        x_train[i,:,:], _=run_dlib_shape(img)\n",
    "        i=i+1\n",
    "\n",
    "    i=0\n",
    "    x_test=np.zeros((len(test[attribute]),68,2))    \n",
    "    for x in list(test['file_name']):\n",
    "        img= image.load_img(img_dir+str(x)+'.png',target_size=None,interpolation='bicubic')\n",
    "        img=image.img_to_array(img)\n",
    "        x_test[i,:,:], _=run_dlib_shape(img)\n",
    "        i=i+1\n",
    "    return x_train,y_train,x_test,y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
